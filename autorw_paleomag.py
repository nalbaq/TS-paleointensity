# -*- coding: utf-8 -*-
"""AutoRW_paleoMag.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-NOagYJbqX5HztSjOD7LHkKJ6HoL--uY
"""
# Automated Rolling Window
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import matplotlib.pyplot as plt
import os
from google.colab import drive
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from datetime import datetime
import seaborn as sns  # Para mejorar los gráficos
from sklearn.model_selection import KFold


from scipy.interpolate import CubicSpline

import warnings
warnings.filterwarnings('ignore')


# Función para crear directorios si no existen
def create_directory(directory_path):
    if not os.path.exists(directory_path):
        os.makedirs(directory_path)
        print(f"Directorio creado: {directory_path}")


# 0. Load data VADM
drive.mount('/content/drive/',force_remount=True),
pint = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/PINTv811.xlsx')

results_base_dir = '/content/drive/MyDrive/VADM_Results'
create_directory(results_base_dir)

filtro_edad = 5
pint_10my = pint[pint['AGE'] <= filtro_edad]
columns_vadm = ['AGE', 'VADM', 'VDM', 'VDM/VADM']
data_vadm = pint_10my[columns_vadm]
data_vadm.sort_values(by='AGE', ascending=True, inplace=True)

# Treatment for null data at VADM, VDM, VDM/VADM
data_vadm.loc[data_vadm['VADM'].isnull() & data_vadm['VDM'].notnull(), 'VADM'] = data_vadm['VDM']
data_vadm.loc[data_vadm['VADM'].isnull() & data_vadm['VDM'].isnull() & data_vadm['VDM/VADM'].notnull(), 'VADM'] = data_vadm['VDM/VADM']
columns= ['AGE', 'VADM']
data_vadm = data_vadm[columns]

# Subchrones de polaridad magnética
subchrones = {
    "C1n (Brunhes)": {"techo": 0.000, "base": 0.773},
    "C1r.1r (Matuyama)": {"techo": 0.773, "base": 0.990},
    "C1r.1n (Jaramillo)": {"techo": 0.990, "base": 1.070},
    "C1r.2r": {"techo": 1.070, "base": 1.180},
    "C1r.2n (Cobb Mountain)": {"techo": 1.180, "base": 1.215},
    "C1r.3r": {"techo": 1.215, "base": 1.775},

    "C2n (Olduvai)": {"techo": 1.775, "base": 1.934},

    "C2r.1r": {"techo": 1.934, "base": 2.116},
    "C2r.1n (Feni)": {"techo": 2.116, "base": 2.140},
    "C2r.2r (Matuyama)": {"techo": 2.140, "base": 2.595},
    "C2An.1n (Gauss)": {"techo": 2.595, "base": 3.032},
    "C2An.1r (Keana)": {"techo": 3.032, "base": 3.116},
    "C2An.2n": {"techo": 3.116, "base": 3.207},
    "C2An.2r (Mammoth)": {"techo": 3.207, "base": 3.330},
    "C2An.3n (Gauss)": {"techo": 3.330, "base": 3.596},
    "C2Ar (Gilbert)": {"techo": 3.596, "base": 4.187},

    "C3n.1n (Cochiti)": {"techo": 4.187, "base": 4.300},
    "C3n.1r": {"techo": 4.300, "base": 4.631},
    "C3n.2n (Nunivak)": {"techo": 4.631, "base": 4.799},
    "C3n.2r": {"techo": 4.799, "base": 4.896},
    "C3n.3n (Sidufjall)": {"techo": 4.896, "base": 4.997},
    "C3n.3r": {"techo": 4.997, "base": 5.235},
    "C3n.4n (Thvera)": {"techo": 5.235, "base": 6.023},
    "C3r (Gilbert)": {"techo": 6.023, "base": 6.272},

    "C3An.1n": {"techo": 6.272, "base": 6.386},
    "C3An.1r": {"techo": 6.386, "base": 6.727},
    "C3An.2n": {"techo": 6.727, "base": 7.104},
    "C3Ar": {"techo": 7.104, "base": 7.214},
    "C3Bn": {"techo": 7.214, "base": 7.262},
    "C3Br.1r": {"techo": 7.262, "base": 7.305},
    "C3Br.1n": {"techo": 7.305, "base": 7.456},
    "C3Br.2r": {"techo": 7.456, "base": 7.499},
    "C3Br.2n": {"techo": 7.499, "base": 7.537},
    "C3Br.3r": {"techo": 7.537, "base": 7.65},
    "C4n.1n": {"techo": 7.65, "base": 7.701},
    "C4n.1r": {"techo": 7.701, "base": 8.125},
    "C4n.2n": {"techo": 8.125, "base": 8.257},
    "C4r.1r": {"techo": 8.257, "base": 8.300},
    "C4r.1n": {"techo": 8.300, "base": 8.771},
    "C4n.2r": {"techo": 8.771, "base": 9.105},
    "C4An": {"techo": 9.105, "base": 9.311},
    "C4Ar.1r": {"techo": 9.311, "base": 9.426},
    "C4Ar.1n": {"techo": 9.426, "base": 9.647},
    "C4Ar.2r": {"techo": 9.647, "base": 9.721},
    "C4Ar.2n": {"techo": 9.721, "base": 9.786},
    "C4Ar.3r": {"techo": 9.786, "base": 9.937},
    "C5n.1n": {"techo": 9.937, "base": 9.984},
    "C5n.1r": {"techo": 9.984, "base": 10.056}
}

def impute_paleointensity(data_vadm, window_step, age_column='AGE', vadm_column='VADM', time_range=5.01):
    """
    Imputes missing paleointensity data (VADM) in a geological timescale.

    Args:
        data_vadm (pandas.DataFrame): DataFrame containing the paleointensity data.  *NO LONGER CSV PATH*
        window_step (float): The window step size in million years (Myr).
        age_column (str): Name of the column containing the age data. Defaults to 'AGE'.
        vadm_column (str): Name of the column containing the VADM data. Defaults to 'VADM'.
        time_range (float): Time range to consider for imputation (in Myr).  Defaults to 5.01.

    Returns:
        pandas.DataFrame: The DataFrame with the 'window', 'mean_VADM', and 'std_VADM' columns added.
                           Returns None if there are errors processing the data.
    """

    # 1. Create the 'window' column
    sequence = np.arange(0, time_range, window_step)
    new_column = pd.Series(np.nan, index=data_vadm.index)
    assignment_limit = min(len(sequence), len(new_column))
    new_column[:assignment_limit] = sequence[:assignment_limit]

    data_vadm['window'] = new_column

    # 2. Calculate mean VADM for each window
    def calculate_mean_vadm(ventana, df, age_column, vadm_column):
        filtered_df = df[(df[age_column] >= 0.00) & (df[age_column] < ventana)]
        if filtered_df.empty:
            return np.nan
        else:
            return filtered_df[vadm_column].mean() # Use filtered_df here!

    data_vadm['mean_VADM'] = data_vadm['window'].apply(lambda x: calculate_mean_vadm(x, data_vadm, age_column, vadm_column))

    # Refine mean_VADM calculation within each window
    unique_ventana_values = sorted(data_vadm['window'].unique())
    for i, ventana_value in enumerate(unique_ventana_values):
        if ventana_value > time_range:
            data_vadm.loc[data_vadm['window'] == ventana_value, 'mean_VADM'] = np.nan
        else:
            lower_limit = 0 if i == 0 else unique_ventana_values[i - 1]
            data_vadm.loc[data_vadm['window'] == ventana_value, 'mean_VADM'] = data_vadm[
                (data_vadm[age_column] >= lower_limit) &
                (data_vadm[age_column] <= ventana_value)
            ][vadm_column].mean()

    # 3. Calculate standard deviation of VADM for each window
    def calculate_std_vadm(ventana, df, age_column, vadm_column):
        filtered_df = df[(df[age_column] >= 0) & (df[age_column] < ventana)] # use filtered_df
        if filtered_df.empty or len(filtered_df) <= 1: # Require at least two points for std
            return np.nan
        else:
            return filtered_df[vadm_column].std(ddof=0) #use filtered_df

    data_vadm['std_VADM'] = data_vadm['window'].apply(lambda x: calculate_std_vadm(x, data_vadm, age_column, vadm_column))

    # Refine std_VADM calculation within each window
    unique_ventana_values = sorted(data_vadm['window'].unique())
    for i, ventana_value in enumerate(unique_ventana_values):
        if ventana_value > time_range:
            data_vadm.loc[data_vadm['window'] == ventana_value, 'std_VADM'] = np.nan
        else:
            lower_limit = 0 if i == 0 else unique_ventana_values[i - 1]
            data_vadm.loc[data_vadm['window'] == ventana_value, 'std_VADM'] = data_vadm[
                (data_vadm[age_column] >= lower_limit) &
                (data_vadm[age_column] <= ventana_value)
            ][vadm_column].std(ddof=0)
    return data_vadm


# 4. Plot mean VADM on rolling window with bar errors


def plot_vadm(df, window_step, output_dir, plot_filename='plot_VADM.png', age_column='window', vadm_mean_column='mean_VADM',
              vadm_std_column='std_VADM', time_range=5.01):
    """
    Plots the mean VADM with error bars representing the standard deviation.

    Args:
        df (pandas.DataFrame): DataFrame containing the 'window', 'mean_VADM', and 'std_VADM' columns.
        window_step (float): Window step size (for x-axis error bars).
        window (float): Window step size *2 (on My).
        output_dir (str): Directory to save the plot.
        plot_filename (str): Filename to save the plot.  Defaults to 'plot_VADM.png'.
        age_column (str): Name of the age column ('window' in this case).
        vadm_mean_column (str): Name of the mean VADM column.
        vadm_std_column (str): Name of the standard deviation VADM column.
        time_range (float): Time range to consider for imputation (in Myr).  Defaults to 5.01.
    """

    df_plot = df.dropna(subset=[vadm_mean_column])
    if df_plot.empty:
        print("Warning: No data to plot after dropping NaN values in 'mean_VADM'. Check your data or window size.")
        return

    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 7), gridspec_kw={'height_ratios': [4, 1]}, sharex=True)

    ax1.set_title(f"Mean VADM with Window Step {window_step*2} for last 5 My", fontsize=15, pad=20)
    ax1.set_ylabel('VADM (x10^22 Am²)', fontsize=12)
    ax1.set_xticks(np.arange(0, 5.01, 0.5))
    ax1.scatter(df_plot[age_column], df_plot[vadm_mean_column], label='PINT', facecolors='none', edgecolors='black', s=8,linewidth=0.4)
    ax1.plot(df_plot[age_column], df_plot[vadm_mean_column], color='cornflowerblue', linestyle='-', linewidth=1.2, label='Mean VADM')
    #ax1.errorbar(df_plot[age_column], df_plot[vadm_mean_column], yerr=df_plot[vadm_std_column], fmt='none', ecolor='gray', elinewidth=0.3, capsize=3, label = 'Standard Deviation')
    #ax1.errorbar(df_plot[age_column], df_plot[vadm_mean_column], xerr=window_step, fmt='none', ecolor='gray', elinewidth=0.3, capsize=3, label = 'Window Step')
    ax1.fill_between(df_plot[age_column], df_plot[vadm_mean_column] - df_plot[vadm_std_column], df_plot[vadm_mean_column] + df_plot[vadm_std_column], color='lightblue', alpha=0.3, label='RW ± σ')

    ax1.grid(True, linestyle='--', linewidth=0.2)
    ax1.legend(loc='upper right', fontsize=10)  # Added a legend
    ax1.set_xlim(0, 5)

    plt.subplots_adjust(hspace=0)

    colores = ["black", "white"] * (len(subchrones) // 2 + 1)

    for i, (subcron, datos) in enumerate(subchrones.items()):
        ax2.barh(0, width=datos["techo"] - datos["base"], left=datos["base"], height=0.6, color=colores[i], edgecolor="black")

    ax2.yaxis.set_visible(False)
    ax2.set_xlabel('Age (Myr)', fontsize=12)

    for spine in ax2.spines.values():
        spine.set_visible(False)

    for subcron, datos in subchrones.items():
        ax2.text((datos["base"] + datos["techo"]) / 2, 0, subcron, ha="center", va="center", color="white" if colores[list(subchrones.keys()).index(subcron)] == "black" else "black", fontsize=7, rotation=90)

    ax2.set_xlim(0, 5)

    full_path = os.path.join(output_dir, plot_filename)
    plt.savefig(full_path, dpi=300)
    print(f"Plot saved to: {full_path}")
    plt.show()



# 5. Calculate metrics of imputed data
def calculate_fit_metric(df, age_column='window', vadm_mean_column='mean_VADM', vadm_column='VADM'):
  """
  Calculates a simple Mean Absolute Error (MAE) metric to assess the fit of the imputed data.
  This compares the imputed mean VADM values to the original VADM values within each window.
  This is a basic example and can be replaced with a more sophisticated metric.
  """
  df_valid = df.dropna(subset=[vadm_mean_column, vadm_column])

  if df_valid.empty:
      print("Warning: No overlapping data points to calculate fit metric.")
      return np.inf

  mae = np.mean(np.abs(df_valid[vadm_column] - df_valid[vadm_mean_column]))
  return mae


def calculate_rmse(df, age_column='window', vadm_mean_column='mean_VADM', vadm_column='VADM'):
  df_valid = df.dropna(subset=[vadm_mean_column, vadm_column])
  if df_valid.empty:
      print("Warning: No overlapping data points to calculate RMSE.")
      return np.inf

  mse = mean_squared_error(df_valid[vadm_column], df_valid[vadm_mean_column])
  rmse = np.sqrt(mse)
  return rmse

def calculate_r_squared(df, age_column='window', vadm_mean_column='mean_VADM', vadm_column='VADM'):
  df_valid = df.dropna(subset=[vadm_mean_column, vadm_column])
  if df_valid.empty:
      print("Warning: No overlapping data points to calculate R-squared.")
      return np.nan

  r2 = r2_score(df_valid[vadm_column], df_valid[vadm_mean_column])
  return r2

def calculate_mape(df, age_column='window', vadm_mean_column='mean_VADM', vadm_column='VADM'):
  df_valid = df.dropna(subset=[vadm_mean_column, vadm_column])
  if df_valid.empty:
      print("Warning: No overlapping data points to calculate MAPE.")
      return np.inf

  actual = df_valid[vadm_column].values
  predicted = df_valid[vadm_mean_column].values

  actual = np.where(actual == 0, 1e-8, actual)

  mape = np.mean(np.abs((actual - predicted) / actual)) * 100
  return mape

if __name__ == "__main__":
    # Lista de window_steps para probar
    window_steps = [0.005, 0.01, 0.05]  # 10ka, 20ka, 100ka respective on My conversion = [0.005, 0.01, 0.05, etc...]

    # Crear directorio con fecha para esta ejecución
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    run_dir = os.path.join(results_base_dir, f"run_{timestamp}")
    create_directory(run_dir)

    # Archivo para guardar métricas de todas las ejecuciones
    metrics_file = os.path.join(run_dir, "metrics_summary.csv")
    metrics_data = []

    # Procesar cada window_step
    for window_step in window_steps:
        print(f"Processing with window_step = {window_step*2}")

        # Crear directorio específico para este window_step
        window_dir = os.path.join(run_dir, f"window_step_{window_step*2}")
        create_directory(window_dir)

        # Impute data
        data_imputed = impute_paleointensity(data_vadm.copy(), window_step)

        if data_imputed is not None:
            # Guardar datos imputados como .xls
            excel_filename = f"imputed_data_window_{window_step}.xls"
            excel_path = os.path.join(window_dir, excel_filename)
            data_imputed.to_excel(excel_path.replace('.xls', '.xlsx'), index=False, engine='openpyxl')
            #data_imputed.to_excel(excel_path, index=False, engine='xlwt')
            print(f"Imputed data saved to: {excel_path}")

            # Generar y guardar gráfico
            plot_filename = f"plot_VADM_window_{window_step*2}.png"
            plot_vadm(data_imputed, window_step, window_dir, plot_filename=plot_filename)

            # Calcular métricas
            mae = calculate_fit_metric(data_imputed)
            rmse = calculate_rmse(data_imputed)
            r2 = calculate_r_squared(data_imputed)
            mape = calculate_mape(data_imputed)

            print(f"Window Step: {window_step*2}, MAE: {mae}, RMSE: {rmse}, R-squared: {r2}, MAPE: {mape}")

            # Guardar métricas en un archivo específico para este window_step
            metrics_window_file = os.path.join(window_dir, f"metrics_window_{window_step*2}.txt")
            with open(metrics_window_file, 'w') as f:
                f.write(f"Window Step: {window_step*2}\n")
                f.write(f"MAE: {mae}\n")
                f.write(f"RMSE: {rmse}\n")
                f.write(f"R-squared: {r2}\n")
                f.write(f"MAPE: {mape}\n")

            # Agregar resultados al resumen
            metrics_data.append({
                'window_step': window_step*2,
                'MAE': mae,
                'RMSE': rmse,
                'R_squared': r2,
                'MAPE': mape
            })
        else:
            print(f"Imputation failed for window_step = {window_step*2}")

    # Guardar resumen de métricas
    if metrics_data:
        metrics_df = pd.DataFrame(metrics_data)
        metrics_df.to_csv(metrics_file, index=False)
        print(f"Metrics summary saved to: {metrics_file}")



# Automated Rolling Window
# Función para crear directorios si no existen
def create_directory(directory_path):
    if not os.path.exists(directory_path):
        os.makedirs(directory_path)
        print(f"Directorio creado: {directory_path}")


# 0. Load data VADM
drive.mount('/content/drive/',force_remount=True),
pint = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/PINTv811.xlsx')

results_base_dir = '/content/drive/MyDrive/VADM_Results'
create_directory(results_base_dir)

filtro_edad = 10 # changed to 10
pint_10my = pint[pint['AGE'] <= filtro_edad]
columns_vadm = ['AGE', 'VADM', 'VDM', 'VDM/VADM']
data_vadm = pint_10my[columns_vadm]
data_vadm.sort_values(by='AGE', ascending=True, inplace=True)

# Treatment for null data at VADM, VDM, VDM/VADM
data_vadm.loc[data_vadm['VADM'].isnull() & data_vadm['VDM'].notnull(), 'VADM'] = data_vadm['VDM']
data_vadm.loc[data_vadm['VADM'].isnull() & data_vadm['VDM'].isnull() & data_vadm['VDM/VADM'].notnull(), 'VADM'] = data_vadm['VDM/VADM']
columns= ['AGE', 'VADM']
data_vadm = data_vadm[columns]

def impute_paleointensity(data_vadm, window_step, age_column='AGE', vadm_column='VADM', time_range=10.01): #Changed to 10
    """
    Imputes missing paleointensity data (VADM) in a geological timescale.

    Args:
        data_vadm (pandas.DataFrame): DataFrame containing the paleointensity data.  *NO LONGER CSV PATH*
        window_step (float): The window step size in million years (Myr).
        age_column (str): Name of the column containing the age data. Defaults to 'AGE'.
        vadm_column (str): Name of the column containing the VADM data. Defaults to 'VADM'.
        time_range (float): Time range to consider for imputation (in Myr).  Defaults to 5.01.

    Returns:
        pandas.DataFrame: The DataFrame with the 'window', 'mean_VADM', and 'std_VADM' columns added.
                           Returns None if there are errors processing the data.
    """

    # 1. Create the 'window' column
    sequence = np.arange(0, time_range, window_step)
    new_column = pd.Series(np.nan, index=data_vadm.index)
    assignment_limit = min(len(sequence), len(new_column))
    new_column[:assignment_limit] = sequence[:assignment_limit]

    data_vadm['window'] = new_column

    # 2. Calculate mean VADM for each window
    def calculate_mean_vadm(ventana, df, age_column, vadm_column):
        filtered_df = df[(df[age_column] >= 0.00) & (df[age_column] < ventana)]
        if filtered_df.empty:
            return np.nan
        else:
            return filtered_df[vadm_column].mean() # Use filtered_df here!

    data_vadm['mean_VADM'] = data_vadm['window'].apply(lambda x: calculate_mean_vadm(x, data_vadm, age_column, vadm_column))

    # Refine mean_VADM calculation within each window
    unique_ventana_values = sorted(data_vadm['window'].unique())
    for i, ventana_value in enumerate(unique_ventana_values):
        if ventana_value > time_range:
            data_vadm.loc[data_vadm['window'] == ventana_value, 'mean_VADM'] = np.nan
        else:
            lower_limit = 0 if i == 0 else unique_ventana_values[i - 1]
            data_vadm.loc[data_vadm['window'] == ventana_value, 'mean_VADM'] = data_vadm[
                (data_vadm[age_column] >= lower_limit) &
                (data_vadm[age_column] <= ventana_value)
            ][vadm_column].mean()

    # 3. Calculate standard deviation of VADM for each window
    def calculate_std_vadm(ventana, df, age_column, vadm_column):
        filtered_df = df[(df[age_column] >= 0) & (df[age_column] < ventana)] # use filtered_df
        if filtered_df.empty or len(filtered_df) <= 1: # Require at least two points for std
            return np.nan
        else:
            return filtered_df[vadm_column].std(ddof=0) #use filtered_df

    data_vadm['std_VADM'] = data_vadm['window'].apply(lambda x: calculate_std_vadm(x, data_vadm, age_column, vadm_column))

    # Refine std_VADM calculation within each window
    unique_ventana_values = sorted(data_vadm['window'].unique())
    for i, ventana_value in enumerate(unique_ventana_values):
        if ventana_value > time_range:
            data_vadm.loc[data_vadm['window'] == ventana_value, 'std_VADM'] = np.nan
        else:
            lower_limit = 0 if i == 0 else unique_ventana_values[i - 1]
            data_vadm.loc[data_vadm['window'] == ventana_value, 'std_VADM'] = data_vadm[
                (data_vadm[age_column] >= lower_limit) &
                (data_vadm[age_column] <= ventana_value)
            ][vadm_column].std(ddof=0)
    return data_vadm


# 4. Plot mean VADM on rolling window with bar errors


def plot_vadm(df, window_step, output_dir, plot_filename='plot_VADM.png', age_column='window', vadm_mean_column='mean_VADM',
              vadm_std_column='std_VADM', time_range=5.01):
    """
    Plots the mean VADM with error bars representing the standard deviation.

    Args:
        df (pandas.DataFrame): DataFrame containing the 'window', 'mean_VADM', and 'std_VADM' columns.
        window_step (float): Window step size (for x-axis error bars).
        window (float): Window step size *2 (on My).
        output_dir (str): Directory to save the plot.
        plot_filename (str): Filename to save the plot.  Defaults to 'plot_VADM.png'.
        age_column (str): Name of the age column ('window' in this case).
        vadm_mean_column (str): Name of the mean VADM column.
        vadm_std_column (str): Name of the standard deviation VADM column.
        time_range (float): Time range to consider for imputation (in Myr).  Defaults to 5.01.
    """

    df_plot = df.dropna(subset=[vadm_mean_column])
    if df_plot.empty:
        print("Warning: No data to plot after dropping NaN values in 'mean_VADM'. Check your data or window size.")
        return

    # Filter data for plotting up to 5My
    df_plot = df_plot[df_plot[age_column] <= 5.0]

    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 7), gridspec_kw={'height_ratios': [4, 1]}, sharex=True)

    ax1.set_title(f"Mean VADM with Window Step {window_step*2} for last 5 My", fontsize=15, pad=20)
    ax1.set_ylabel('VADM (x10^22 Am²)', fontsize=12)
    ax1.set_xticks(np.arange(0, 5.01, 0.5))
    ax1.scatter(df_plot[age_column], df_plot[vadm_mean_column], label='PINT', facecolors='none', edgecolors='black', s=8,linewidth=0.4)
    ax1.plot(df_plot[age_column], df_plot[vadm_mean_column], color='cornflowerblue', linestyle='-', linewidth=1.2, label='Mean VADM')
    #ax1.errorbar(df_plot[age_column], df_plot[vadm_mean_column], yerr=df_plot[vadm_std_column], fmt='none', ecolor='gray', elinewidth=0.3, capsize=3, label = 'Standard Deviation')
    #ax1.errorbar(df_plot[age_column], df_plot[vadm_mean_column], xerr=window_step, fmt='none', ecolor='gray', elinewidth=0.3, capsize=3, label = 'Window Step')
    ax1.fill_between(df_plot[age_column], df_plot[vadm_mean_column] - df_plot[vadm_std_column], df_plot[vadm_mean_column] + df_plot[vadm_std_column], color='lightblue', alpha=0.3, label='RW ± σ')

    ax1.grid(True, linestyle='--', linewidth=0.2)
    ax1.legend(loc='upper right', fontsize=10)  # Added a legend
    ax1.set_xlim(0, 5)

    plt.subplots_adjust(hspace=0)

    colores = ["black", "white"] * (len(subchrones) // 2 + 1)

    for i, (subcron, datos) in enumerate(subchrones.items()):
      if datos["techo"] <= 5.0: #Filter the subchrones temporal axis until 5.0 My
        ax2.barh(0, width=datos["techo"] - datos["base"], left=datos["base"], height=0.6, color=colores[i], edgecolor="black")

    ax2.yaxis.set_visible(False)
    ax2.set_xlabel('Age (Myr)', fontsize=12)

    for spine in ax2.spines.values():
        spine.set_visible(False)

    for subcron, datos in subchrones.items():
        if datos["techo"] <= 5.0 and subcron != "C3n.3r": #Filter the subchrones names on temporal axis until 5.0 My
          ax2.text((datos["base"] + datos["techo"]) / 2, 0, subcron, ha="center", va="center", color="white" if colores[list(subchrones.keys()).index(subcron)] == "black" else "black", fontsize=7, rotation=90)

    ax2.set_xlim(0, 5)

    full_path = os.path.join(output_dir, plot_filename)
    plt.savefig(full_path, dpi=300)
    print(f"Plot saved to: {full_path}")
    plt.show()



# 5. Calculate metrics of imputed data
def calculate_fit_metric(df, age_column='window', vadm_mean_column='mean_VADM', vadm_column='VADM'):
  """
  Calculates a simple Mean Absolute Error (MAE) metric to assess the fit of the imputed data.
  This compares the imputed mean VADM values to the original VADM values within each window.
  This is a basic example and can be replaced with a more sophisticated metric.
  """
  df_valid = df.dropna(subset=[vadm_mean_column, vadm_column])
  df_valid = df_valid[df_valid[age_column] <= 5.0]  # Filter for 5My for metrics

  if df_valid.empty:
      print("Warning: No overlapping data points to calculate fit metric.")
      return np.inf

  mae = np.mean(np.abs(df_valid[vadm_column] - df_valid[vadm_mean_column]))
  return mae


def calculate_rmse(df, age_column='window', vadm_mean_column='mean_VADM', vadm_column='VADM'):
  df_valid = df.dropna(subset=[vadm_mean_column, vadm_column])
  df_valid = df_valid[df_valid[age_column] <= 5.0]  # Filter for 5My for metrics
  if df_valid.empty:
      print("Warning: No overlapping data points to calculate RMSE.")
      return np.inf

  mse = mean_squared_error(df_valid[vadm_column], df_valid[vadm_mean_column])
  rmse = np.sqrt(mse)
  return rmse

def calculate_r_squared(df, age_column='window', vadm_mean_column='mean_VADM', vadm_column='VADM'):
  df_valid = df.dropna(subset=[vadm_mean_column, vadm_column])
  df_valid = df_valid[df_valid[age_column] <= 5.0]  # Filter for 5My for metrics
  if df_valid.empty:
      print("Warning: No overlapping data points to calculate R-squared.")
      return np.nan

  r2 = r2_score(df_valid[vadm_column], df_valid[vadm_mean_column])
  return r2

def calculate_mape(df, age_column='window', vadm_mean_column='mean_VADM', vadm_column='VADM'):
  df_valid = df.dropna(subset=[vadm_mean_column, vadm_column])
  df_valid = df_valid[df_valid[age_column] <= 5.0]  # Filter for 5My for metrics
  if df_valid.empty:
      print("Warning: No overlapping data points to calculate MAPE.")
      return np.inf

  actual = df_valid[vadm_column].values
  predicted = df_valid[vadm_mean_column].values

  actual = np.where(actual == 0, 1e-8, actual)

  mape = np.mean(np.abs((actual - predicted) / actual)) * 100
  return mape

if __name__ == "__main__":
    # Lista de window_steps para probar
    window_steps = [0.005, 0.01, 0.05]  # 10ka, 20ka, 100ka respective on My conversion = [0.005, 0.01, 0.05, etc...]

    # Crear directorio con fecha para esta ejecución
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    run_dir = os.path.join(results_base_dir, f"run_{timestamp}")
    create_directory(run_dir)

    # Archivo para guardar métricas de todas las ejecuciones
    metrics_file = os.path.join(run_dir, "metrics_summary.csv")
    metrics_data = []

    # Procesar cada window_step
    for window_step in window_steps:
        print(f"Processing with window_step = {window_step*2}")

        # Crear directorio específico para este window_step
        window_dir = os.path.join(run_dir, f"window_step_{window_step*2}")
        create_directory(window_dir)

        # Impute data
        data_imputed = impute_paleointensity(data_vadm.copy(), window_step)

        if data_imputed is not None:
            # Guardar datos imputados como .xls
            excel_filename = f"imputed_data_window_{window_step}.xls"
            excel_path = os.path.join(window_dir, excel_filename)
            data_imputed.to_excel(excel_path.replace('.xls', '.xlsx'), index=False, engine='openpyxl')
            #data_imputed.to_excel(excel_path, index=False, engine='xlwt')
            print(f"Imputed data saved to: {excel_path}")

            # Generar y guardar gráfico
            plot_filename = f"plot_VADM_window_{window_step*2}.png"
            plot_vadm(data_imputed, window_step, window_dir, plot_filename=plot_filename)

            # Calcular métricas
            mae = calculate_fit_metric(data_imputed)
            rmse = calculate_rmse(data_imputed)
            r2 = calculate_r_squared(data_imputed)
            mape = calculate_mape(data_imputed)

            print(f"Window Step: {window_step*2}, MAE: {mae}, RMSE: {rmse}, R-squared: {r2}, MAPE: {mape}")

            # Guardar métricas en un archivo específico para este window_step
            metrics_window_file = os.path.join(window_dir, f"metrics_window_{window_step*2}.txt")
            with open(metrics_window_file, 'w') as f:
                f.write(f"Window Step: {window_step*2}\n")
                f.write(f"MAE: {mae}\n")
                f.write(f"RMSE: {rmse}\n")
                f.write(f"R-squared: {r2}\n")
                f.write(f"MAPE: {mape}\n")

            # Agregar resultados al resumen
            metrics_data.append({
                'window_step': window_step*2,
                'MAE': mae,
                'RMSE': rmse,
                'R_squared': r2,
                'MAPE': mape
            })
        else:
            print(f"Imputation failed for window_step = {window_step*2}")

    # Guardar resumen de métricas
    if metrics_data:
        metrics_df = pd.DataFrame(metrics_data)
        metrics_df.to_csv(metrics_file, index=False)
        print(f"Metrics summary saved to: {metrics_file}")





# Automated Rolling Window
# Función para crear directorios si no existen
def create_directory(directory_path):
    if not os.path.exists(directory_path):
        os.makedirs(directory_path)
        print(f"Directorio creado: {directory_path}")

# 0. Load data VADM
drive.mount('/content/drive/', force_remount=True)
pint = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/PINTv811.xlsx')

results_base_dir = '/content/drive/MyDrive/VADM_Results'
create_directory(results_base_dir)

filtro_edad = 10  # changed to 10
pint_10my = pint[pint['AGE'] <= filtro_edad]
columns_vadm = ['AGE', 'VADM', 'VDM', 'VDM/VADM']
data_vadm = pint_10my[columns_vadm]
data_vadm.sort_values(by='AGE', ascending=True, inplace=True)

# Treatment for null data at VADM, VDM, VDM/VADM
data_vadm.loc[data_vadm['VADM'].isnull() & data_vadm['VDM'].notnull(), 'VADM'] = data_vadm['VDM']
data_vadm.loc[data_vadm['VADM'].isnull() & data_vadm['VDM'].isnull() & data_vadm['VDM/VADM'].notnull(), 'VADM'] = data_vadm['VDM/VADM']
columns = ['AGE', 'VADM']
data_vadm = data_vadm[columns]

def impute_paleointensity(data_vadm, window_step, age_column='AGE', vadm_column='VADM', time_range=10.01):  # Changed to 10
    """
    Imputes missing paleointensity data (VADM) in a geological timescale.

    Args:
        data_vadm (pandas.DataFrame): DataFrame containing the paleointensity data.  *NO LONGER CSV PATH*
        window_step (float): The window step size in million years (Myr).
        age_column (str): Name of the column containing the age data. Defaults to 'AGE'.
        vadm_column (str): Name of the column containing the VADM data. Defaults to 'VADM'.
        time_range (float): Time range to consider for imputation (in Myr).  Defaults to 5.01.

    Returns:
        pandas.DataFrame: The DataFrame with the 'window', 'mean_VADM', and 'std_VADM' columns added.
                           Returns None if there are errors processing the data.
    """

    # 1. Create the 'window' column
    sequence = np.arange(0, time_range, window_step)
    new_column = pd.Series(np.nan, index=data_vadm.index)
    assignment_limit = min(len(sequence), len(new_column))
    new_column[:assignment_limit] = sequence[:assignment_limit]

    data_vadm['window'] = new_column

    # 2. Calculate mean VADM for each window
    def calculate_mean_vadm(ventana, df, age_column, vadm_column):
        filtered_df = df[(df[age_column] >= 0.00) & (df[age_column] < ventana)]
        if filtered_df.empty:
            return np.nan
        else:
            return filtered_df[vadm_column].mean()  # Use filtered_df here!

    data_vadm['mean_VADM'] = data_vadm['window'].apply(lambda x: calculate_mean_vadm(x, data_vadm, age_column, vadm_column))

    # Refine mean_VADM calculation within each window
    unique_ventana_values = sorted(data_vadm['window'].unique())
    for i, ventana_value in enumerate(unique_ventana_values):
        if ventana_value > time_range:
            data_vadm.loc[data_vadm['window'] == ventana_value, 'mean_VADM'] = np.nan
        else:
            lower_limit = 0 if i == 0 else unique_ventana_values[i - 1]
            data_vadm.loc[data_vadm['window'] == ventana_value, 'mean_VADM'] = data_vadm[
                (data_vadm[age_column] >= lower_limit) &
                (data_vadm[age_column] <= ventana_value)
            ][vadm_column].mean()

    # 3. Calculate standard deviation of VADM for each window
    def calculate_std_vadm(ventana, df, age_column, vadm_column):
        filtered_df = df[(df[age_column] >= 0) & (df[age_column] < ventana)]  # use filtered_df
        if filtered_df.empty or len(filtered_df) <= 1:  # Require at least two points for std
            return np.nan
        else:
            return filtered_df[vadm_column].std(ddof=0)  # use filtered_df

    data_vadm['std_VADM'] = data_vadm['window'].apply(lambda x: calculate_std_vadm(x, data_vadm, age_column, vadm_column))

    # Refine std_VADM calculation within each window
    unique_ventana_values = sorted(data_vadm['window'].unique())
    for i, ventana_value in enumerate(unique_ventana_values):
        if ventana_value > time_range:
            data_vadm.loc[data_vadm['window'] == ventana_value, 'std_VADM'] = np.nan
        else:
            lower_limit = 0 if i == 0 else unique_ventana_values[i - 1]
            data_vadm.loc[data_vadm['window'] == ventana_value, 'std_VADM'] = data_vadm[
                (data_vadm[age_column] >= lower_limit) &
                (data_vadm[age_column] <= ventana_value)
            ][vadm_column].std(ddof=0)
    return data_vadm

# 4. Plot mean VADM on rolling window with bar errors
def plot_vadm(df, window_step, output_dir, plot_filename='plot_VADM.png', age_column='window', vadm_mean_column='mean_VADM',
              vadm_std_column='std_VADM', time_range=5.01):
    """
    Plots the mean VADM with error bars representing the standard deviation.

    Args:
        df (pandas.DataFrame): DataFrame containing the 'window', 'mean_VADM', and 'std_VADM' columns.
        window_step (float): Window step size (for x-axis error bars).
        window (float): Window step size *2 (on My).
        output_dir (str): Directory to save the plot.
        plot_filename (str): Filename to save the plot.  Defaults to 'plot_VADM.png'.
        age_column (str): Name of the age column ('window' in this case).
        vadm_mean_column (str): Name of the mean VADM column.
        vadm_std_column (str): Name of the standard deviation VADM column.
        time_range (float): Time range to consider for imputation (in Myr).  Defaults to 5.01.
    """

    df_plot = df.dropna(subset=[vadm_mean_column])
    if df_plot.empty:
        print("Warning: No data to plot after dropping NaN values in 'mean_VADM'. Check your data or window size.")
        return

    # Filter data for plotting up to 5My
    df_plot = df_plot[df_plot[age_column] <= 5.0]

    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 7), gridspec_kw={'height_ratios': [4, 1]}, sharex=True)

    ax1.set_title(f"Mean VADM with Window Step {window_step*2} for last 5 My", fontsize=15, pad=20)
    ax1.set_ylabel('VADM (x10^22 Am²)', fontsize=12)
    ax1.set_xticks(np.arange(0, 5.01, 0.5))
    ax1.scatter(df_plot[age_column], df_plot[vadm_mean_column], label='PINT', facecolors='none', edgecolors='black', s=8, linewidth=0.4)
    ax1.plot(df_plot[age_column], df_plot[vadm_mean_column], color='cornflowerblue', linestyle='-', linewidth=1.2, label='Mean VADM')
    # ax1.errorbar(df_plot[age_column], df_plot[vadm_mean_column], yerr=df_plot[vadm_std_column], fmt='none', ecolor='gray', elinewidth=0.3, capsize=3, label = 'Standard Deviation')
    # ax1.errorbar(df_plot[age_column], df_plot[vadm_mean_column], xerr=window_step, fmt='none', ecolor='gray', elinewidth=0.3, capsize=3, label = 'Window Step')
    ax1.fill_between(df_plot[age_column], df_plot[vadm_mean_column] - df_plot[vadm_std_column], df_plot[vadm_mean_column] + df_plot[vadm_std_column], color='lightblue', alpha=0.3, label='RW ± σ')

    ax1.grid(True, linestyle='--', linewidth=0.2)
    ax1.legend(loc='upper right', fontsize=10)  # Added a legend
    ax1.set_xlim(0, 5)

    plt.subplots_adjust(hspace=0)

    colores = ["black", "white"] * (len(subchrones) // 2 + 1)

    for i, (subcron, datos) in enumerate(subchrones.items()):
        if datos["techo"] <= 5.0:  # Filter the subchrones temporal axis until 5.0 My
            ax2.barh(0, width=datos["techo"] - datos["base"], left=datos["base"], height=0.6, color=colores[i], edgecolor="black")

    ax2.yaxis.set_visible(False)
    ax2.set_xlabel('Age (Myr)', fontsize=12)

    for spine in ax2.spines.values():
        spine.set_visible(False)

    for subcron, datos in subchrones.items():
        if datos["techo"] <= 5.0 and subcron != "C3n.3r":  # Filter the subchrones names on temporal axis until 5.0 My
            ax2.text((datos["base"] + datos["techo"]) / 2, 0, subcron, ha="center", va="center", color="white" if colores[list(subchrones.keys()).index(subcron)] == "black" else "black", fontsize=7, rotation=90)

    ax2.set_xlim(0, 5)

    full_path = os.path.join(output_dir, plot_filename)
    plt.savefig(full_path, dpi=300)
    print(f"Plot saved to: {full_path}")
    plt.show()

# Nueva función para crear el plot combinado
def plot_all_windows(data_vadm, data_imputed_list, window_steps, output_dir, filename="all_windows.png"):
    """Plots all rolling window results, the original data, and subchrons on a single plot."""
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 7), gridspec_kw={'height_ratios': [4, 1]}, sharex=True)

    ax1.set_title("VADM vs AGE with distinct Rolling Windows", fontsize=15, pad=20)
    ax1.set_ylabel('VADM (x10^22 Am²)', fontsize=12)
    ax1.set_xlim(0, 5)
    ax1.set_xticks(np.arange(0, 5.01, 0.5))
    ax1.grid(True, linestyle='--', linewidth=0.2)

    # Scatter plot de la data original
    ax1.scatter(data_vadm['AGE'], data_vadm['VADM'], label='PINT', facecolors='none', edgecolors='black', s=8, linewidth=0.2)

    # Colores para las curvas de rolling window
    colors = ['seagreen', 'royalblue', 'darkviolet']  # Asegúrate de que haya suficientes colores

    # Plot de las curvas de rolling window
    for i, data_imputed in enumerate(data_imputed_list):
        df_plot = data_imputed.dropna(subset=['mean_VADM'])
        df_plot = df_plot[df_plot['window'] <= 5.0]
        ax1.plot(df_plot['window'], df_plot['mean_VADM'], color=colors[i], linestyle='-', linewidth=0.8, label=f'RW {window_steps[i]*2} ka')

    ax1.legend(loc='upper right', fontsize=10)

    # Subplot de los subchrones (eje x temporal)
    colores = ["black", "white"] * (len(subchrones) // 2 + 1)

    for i, (subcron, datos) in enumerate(subchrones.items()):
        if datos["techo"] <= 5.0:  # Filter the subchrones temporal axis until 5.0 My
            ax2.barh(0, width=datos["techo"] - datos["base"], left=datos["base"], height=0.6, color=colores[i], edgecolor="black")

    ax2.yaxis.set_visible(False)
    ax2.set_xlabel('Age (Myr)', fontsize=12)

    for spine in ax2.spines.values():
        spine.set_visible(False)

    for subcron, datos in subchrones.items():
        if datos["techo"] <= 5.0 and subcron != "C3n.3r":  # Filter the subchrones names on temporal axis until 5.0 My
            ax2.text((datos["base"] + datos["techo"]) / 2, 0, subcron, ha="center", va="center", color="white" if colores[list(subchrones.keys()).index(subcron)] == "black" else "black", fontsize=7, rotation=90)

    ax2.set_xlim(0, 5)

    plt.subplots_adjust(hspace=0)

    # Guardar la figura
    full_path = os.path.join(output_dir, filename)
    plt.savefig(full_path, dpi=300)
    print(f"Combined plot saved to: {full_path}")
    plt.show()

# 5. Calculate metrics of imputed data
def calculate_fit_metric(df, age_column='window', vadm_mean_column='mean_VADM', vadm_column='VADM'):
    """
    Calculates a simple Mean Absolute Error (MAE) metric to assess the fit of the imputed data.
    This compares the imputed mean VADM values to the original VADM values within each window.
    This is a basic example and can be replaced with a more sophisticated metric.
    """
    df_valid = df.dropna(subset=[vadm_mean_column, vadm_column])
    df_valid = df_valid[df_valid[age_column] <= 5.0]  # Filter for 5My for metrics

    if df_valid.empty:
        print("Warning: No overlapping data points to calculate fit metric.")
        return np.inf

    mae = np.mean(np.abs(df_valid[vadm_column] - df_valid[vadm_mean_column]))
    return mae

def calculate_rmse(df, age_column='window', vadm_mean_column='mean_VADM', vadm_column='VADM'):
    df_valid = df.dropna(subset=[vadm_mean_column, vadm_column])
    df_valid = df_valid[df_valid[age_column] <= 5.0]  # Filter for 5My for metrics
    if df_valid.empty:
        print("Warning: No overlapping data points to calculate RMSE.")
        return np.inf

    mse = mean_squared_error(df_valid[vadm_column], df_valid[vadm_mean_column])
    rmse = np.sqrt(mse)
    return rmse

def calculate_r_squared(df, age_column='window', vadm_mean_column='mean_VADM', vadm_column='VADM'):
    df_valid = df.dropna(subset=[vadm_mean_column, vadm_column])
    df_valid = df_valid[df_valid[age_column] <= 5.0]  # Filter for 5My for metrics
    if df_valid.empty:
        print("Warning: No overlapping data points to calculate R-squared.")
        return np.nan

    r2 = r2_score(df_valid[vadm_column], df_valid[vadm_mean_column])
    return r2

def calculate_mape(df, age_column='window', vadm_mean_column='mean_VADM', vadm_column='VADM'):
    df_valid = df.dropna(subset=[vadm_mean_column, vadm_column])
    df_valid = df_valid[df_valid[age_column] <= 5.0]  # Filter for 5My for metrics
    if df_valid.empty:
        print("Warning: No overlapping data points to calculate MAPE.")
        return np.inf

    actual = df_valid[vadm_column].values
    predicted = df_valid[vadm_mean_column].values

    actual = np.where(actual == 0, 1e-8, actual)

    mape = np.mean(np.abs((actual - predicted) / actual)) * 100
    return mape

if __name__ == "__main__":
    # Lista de window_steps para probar
    window_steps = [0.005, 0.01, 0.05]  # 10ka, 20ka, 100ka respective on My conversion = [0.005, 0.01, 0.05, etc...]

    # Crear directorio con fecha para esta ejecución
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    run_dir = os.path.join(results_base_dir, f"run_{timestamp}")
    create_directory(run_dir)

    # Archivo para guardar métricas de todas las ejecuciones
    metrics_file = os.path.join(run_dir, "metrics_summary.csv")
    metrics_data = []
    data_imputed_list = []

    # Procesar cada window_step
    for window_step in window_steps:
        print(f"Processing with window_step = {window_step*2}")

        # Crear directorio específico para este window_step
        window_dir = os.path.join(run_dir, f"window_step_{window_step*2}")
        create_directory(window_dir)

        # Impute data
        data_imputed = impute_paleointensity(data_vadm.copy(), window_step)
        data_imputed_list.append(data_imputed)

        if data_imputed is not None:
            # Guardar datos imputados como .xls
            excel_filename = f"imputed_data_window_{window_step}.xls"
            excel_path = os.path.join(window_dir, excel_filename)
            data_imputed.to_excel(excel_path.replace('.xls', '.xlsx'), index=False, engine='openpyxl')
            # data_imputed.to_excel(excel_path, index=False, engine='xlwt')
            print(f"Imputed data saved to: {excel_path}")

            # Generar y guardar gráfico
            plot_filename = f"plot_VADM_window_{window_step*2}.png"
            plot_vadm(data_imputed, window_step, window_dir, plot_filename=plot_filename)

            # Calcular métricas
            mae = calculate_fit_metric(data_imputed)
            rmse = calculate_rmse(data_imputed)
            r2 = calculate_r_squared(data_imputed)
            mape = calculate_mape(data_imputed)

            print(f"Window Step: {window_step*2}, MAE: {mae}, RMSE: {rmse}, R-squared: {r2}, MAPE: {mape}")

            # Guardar métricas en un archivo específico para este window_step
            metrics_window_file = os.path.join(window_dir, f"metrics_window_{window_step*2}.txt")
            with open(metrics_window_file, 'w') as f:
                f.write(f"Window Step: {window_step*2}\n")
                f.write(f"MAE: {mae}\n")
                f.write(f"RMSE: {rmse}\n")
                f.write(f"R-squared: {r2}\n")
                f.write(f"MAPE: {mape}\n")

            # Agregar resultados al resumen
            metrics_data.append({
                'window_step': window_step*2,
                'MAE': mae,
                'RMSE': rmse,
                'R_squared': r2,
                'MAPE': mape
            })
        else:
            print(f"Imputation failed for window_step = {window_step*2}")

    # Guardar resumen de métricas
    if metrics_data:
        metrics_df = pd.DataFrame(metrics_data)
        metrics_df.to_csv(metrics_file, index=False)
        print(f"Metrics summary saved to: {metrics_file}")

    # Generar el plot combinado
    plot_all_windows(data_vadm, data_imputed_list, window_steps, run_dir)

# Automated Rolling Window with Bootstrap Analysis
# Función para crear directorios si no existen
def create_directory(directory_path):
    if not os.path.exists(directory_path):
        os.makedirs(directory_path)
        print(f"Directorio creado: {directory_path}")

# Función para realizar el bootstrap y calcular métricas
def perform_bootstrap(data, n_bootstraps=100, window_step=0.05, age_column='AGE', vadm_column='VADM'):
    """Realiza el bootstrap y calcula las métricas."""
    metrics_list = []
    bootstrap_results = []
    original_rate_df = calculate_vadm_rate_of_change(data.copy(), window_step, age_column, vadm_column)

    for i in range(n_bootstraps):
        # Resample con reemplazo
        bootstrap_sample = data.sample(n=len(data), replace=True, random_state=i)
        bootstrap_rate_df = calculate_vadm_rate_of_change(bootstrap_sample.copy(), window_step, age_column, vadm_column)
        bootstrap_results.append(bootstrap_rate_df)

        # Calcular métricas comparando con la curva original
        merged_df = pd.merge(original_rate_df, bootstrap_rate_df, on=age_column, suffixes=('_original', '_bootstrap'), how='inner')
        if not merged_df.empty:
            # Eliminar filas donde cualquiera de las dos columnas de tasa de cambio es NaN
            valid_rows = merged_df.dropna(subset=['VADM_rate_of_change_original', 'VADM_rate_of_change_bootstrap'])
            if not valid_rows.empty:
                mae = mean_absolute_error(valid_rows['VADM_rate_of_change_original'], valid_rows['VADM_rate_of_change_bootstrap'])
                mse = mean_squared_error(valid_rows['VADM_rate_of_change_original'], valid_rows['VADM_rate_of_change_bootstrap'])
                r2 = r2_score(valid_rows['VADM_rate_of_change_original'], valid_rows['VADM_rate_of_change_bootstrap'])
                metrics_list.append({'bootstrap': i + 1, 'mae': mae, 'mse': mse, 'r2': r2, 'n_bootstrap': n_bootstraps})
            else:
                metrics_list.append({'bootstrap': i + 1, 'mae': np.nan, 'mse': np.nan, 'r2': np.nan, 'n_bootstrap': n_bootstraps})
        else:
            metrics_list.append({'bootstrap': i + 1, 'mae': np.nan, 'mse': np.nan, 'r2': np.nan, 'n_bootstrap': n_bootstraps})

    metrics_df = pd.DataFrame(metrics_list)
    return bootstrap_results, metrics_df, original_rate_df

# Función para calcular la tasa de cambio de VADM usando una ventana móvil
def calculate_vadm_rate_of_change(data_vadm, window_step, age_column='AGE', vadm_column='VADM'):
    """Calcula la tasa de cambio de VADM usando una ventana móvil."""
    data = data_vadm.sort_values(by=age_column).copy()
    half_window = window_step

    rate_of_change = []
    ages = []
    for i in range(len(data)):
        center_age = data[age_column].iloc[i]
        start_age = center_age - half_window
        end_age = center_age + half_window
        window_data = data[(data[age_column] >= start_age) & (data[age_column] <= end_age)]

        if len(window_data) < 2:
            rate_of_change.append(np.nan)
            ages.append(center_age)
            continue

        slope, intercept = np.polyfit(window_data[age_column], window_data[vadm_column], 1)
        rate_of_change.append(slope)
        ages.append(center_age)

    rate_df = pd.DataFrame({
        age_column: ages,
        'VADM_rate_of_change': rate_of_change
    })
    return rate_df

# Función para graficar la curva de bootstrap y el scatter de PINT
def plot_bootstrap_curve(original_data, best_bootstrap_rate, pint_data, output_dir, filename="best_bootstrap_curve.png"):
    """Grafica la curva de bootstrap que mejor se ajustó junto con el scatter de PINT."""
    plt.figure(figsize=(12, 6))
    plt.scatter(pint_data['AGE'], pint_data['VADM'], alpha=0.6, label='PINT Data')
    plt.plot(best_bootstrap_rate['AGE'], best_bootstrap_rate['VADM_rate_of_change'], color='red', label='Best Bootstrap Curve')
    plt.xlabel('Age (Myr)')
    plt.ylabel('VADM')
    plt.title('Best Bootstrap Curve and PINT Data')
    plt.legend()
    plt.grid(True, linestyle='--', linewidth=0.5)
    full_path = os.path.join(output_dir, filename)
    plt.savefig(full_path, dpi=300)
    print(f"Best Bootstrap Curve plot saved to: {full_path}")
    plt.close()

# Función para graficar la tasa de cambio de VADM y subchrones
def plot_vadm_rate_of_change_with_subchrons(rate_df, window_step, output_dir, subchrones, filename="vadm_rate_of_change_with_subchrons.png"):
    """Grafica la tasa de cambio de VADM y los subchrones."""
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 7), gridspec_kw={'height_ratios': [4, 1]}, sharex=True)

    ax1.set_title(f"VADM Rate of Change (Window = {window_step*2} Myr)", fontsize=15, pad=20)
    ax1.set_ylabel('Rate of Change (VADM / Myr)', fontsize=12)
    ax1.set_xlim(0, 5)
    ax1.set_xticks(np.arange(0, 5.01, 0.5))
    ax1.grid(True, linestyle='--', linewidth=0.2)
    ax1.plot(rate_df['AGE'], rate_df['VADM_rate_of_change'], color='mediumvioletred', linestyle='-', linewidth=1)

    # Subplot de los subchrones (eje x temporal)
    colores = ["black", "white"] * (len(subchrones) // 2 + 1)
    for i, (subcron, datos) in enumerate(subchrones.items()):
        if datos["techo"] <= 5.0:
            ax2.barh(0, width=datos["techo"] - datos["base"], left=datos["base"], height=0.6, color=colores[i], edgecolor="black")

    ax2.yaxis.set_visible(False)
    ax2.set_xlabel('Age (Myr)', fontsize=12)
    for spine in ax2.spines.values():
        spine.set_visible(False)
    for subcron, datos in subchrones.items():
        if datos["techo"] <= 5.0 and subcron != "C3n.3r":
            ax2.text((datos["base"] + datos["techo"]) / 2, 0, subcron, ha="center", va="center", color="white" if colores[list(subchrones.keys()).index(subcron)] == "black" else "black", fontsize=7, rotation=90)

    ax2.set_xlim(0, 5)
    plt.subplots_adjust(hspace=0)

    full_path = os.path.join(output_dir, filename)
    plt.savefig(full_path, dpi=300)
    print(f"VADM Rate of Change with Subchrons plot saved to: {full_path}")
    plt.close()

# Función para graficar métricas vs número de bootstraps
def plot_metrics_vs_n_bootstrap(metrics_df, output_dir, filename="metrics_vs_n_bootstrap.png"):
    """Grafica las métricas (MAE, MSE, R2) en función del número de bootstraps."""
    n_bootstraps_unique = metrics_df['n_bootstrap'].unique()
    if len(n_bootstraps_unique) > 1:
        plt.figure(figsize=(10, 6))
        for metric in ['mae', 'mse', 'r2']:
            sns.lineplot(x='n_bootstrap', y=metric, data=metrics_df, label=metric.upper())
        plt.xlabel('Number of Bootstraps (n)')
        plt.ylabel('Metric Value')
        plt.title('Metrics vs. Number of Bootstraps')
        plt.legend()
        plt.grid(True, linestyle='--', linewidth=0.5)
        full_path = os.path.join(output_dir, filename)
        plt.savefig(full_path, dpi=300)
        print(f"Metrics vs. N Bootstrap plot saved to: {full_path}")
        plt.close()
    else:
        print("Solo se realizó un valor de n_bootstrap, no se puede generar el gráfico de métricas vs n.")

# Función para evaluar la estabilidad de la métrica alrededor del mejor 'n'
def evaluate_stability(data, best_n, window_step, age_column='AGE', vadm_column='VADM'):
    """Evalúa la estabilidad de la métrica alrededor del mejor 'n'."""
    n_values_stability = list(range(max(1, best_n - 2), best_n + 3))
    stability_metrics = []
    for n in n_values_stability:
        _, metrics_df, _ = perform_bootstrap(data.copy(), n_bootstraps=n, window_step=window_step, age_column=age_column, vadm_column=vadm_column)
        # Tomamos la media de las métricas para este n
        mean_metrics = metrics_df[['mae', 'mse', 'r2']].mean().to_dict()
        mean_metrics['n_bootstrap'] = n
        stability_metrics.append(mean_metrics)
    return pd.DataFrame(stability_metrics)

# Función para graficar la estabilidad de la métrica
def plot_stability_metrics(stability_df, output_dir, filename="stability_metrics.png"):
    """Grafica la estabilidad de las métricas alrededor del mejor n."""
    if not stability_df.empty:
        plt.figure(figsize=(10, 6))
        for metric in ['mae', 'mse', 'r2']:
            plt.plot(stability_df['n_bootstrap'], stability_df[metric], marker='o', label=metric.upper())
        plt.xlabel('Number of Bootstraps (n)')
        plt.ylabel('Mean Metric Value')
        plt.title('Stability of Metrics Around Best n')
        plt.legend()
        plt.grid(True, linestyle='--', linewidth=0.5)
        full_path = os.path.join(output_dir, filename)
        plt.savefig(full_path, dpi=300)
        print(f"Stability Metrics plot saved to: {full_path}")
        plt.close()
    else:
        print("No se pudieron calcular las métricas de estabilidad.")

if __name__ == "__main__":
    # 0. Load data VADM
    drive.mount('/content/drive/', force_remount=True)
    pint = pd.read_excel('/content/drive/MyDrive/Colab Notebooks/PINTv811.xlsx')

    results_base_dir = '/content/drive/MyDrive/VADM_Results'
    create_directory(results_base_dir)
    run_dir = os.path.join(results_base_dir, f"bootstrap_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
    create_directory(run_dir)

    filtro_edad = 10
    pint_10my = pint[pint['AGE'] <= filtro_edad]
    columns_vadm = ['AGE', 'VADM', 'VDM', 'VDM/VADM']
    data_vadm = pint_10my[columns_vadm].copy() # Usar .copy() para evitar SettingWithCopyWarning
    data_vadm.sort_values(by='AGE', ascending=True, inplace=True)

    # Treatment for null data at VADM, VDM, VDM/VADM
    data_vadm.loc[data_vadm['VADM'].isnull() & data_vadm['VDM'].notnull(), 'VADM'] = data_vadm['VDM']
    data_vadm.loc[data_vadm['VADM'].isnull() & data_vadm['VDM'].isnull() & data_vadm['VDM/VADM'].notnull(), 'VADM'] = data_vadm['VDM/VADM']
    columns = ['AGE', 'VADM']
    data_vadm_clean = data_vadm[columns].copy().dropna() # Asegurarse de no tener NaNs para el bootstrap

    n_bootstraps_values = [1,10, 20,50, 100, 200]
    all_metrics = []
    all_bootstrap_results = {}

    for n_bootstraps in n_bootstraps_values:
        print(f"Realizando bootstrap con n = {n_bootstraps}")
        bootstrap_results, metrics_df, _ = perform_bootstrap(data_vadm_clean, n_bootstraps=n_bootstraps, window_step=0.05)
        metrics_df['n_bootstrap'] = n_bootstraps
        all_metrics.append(metrics_df)
        all_bootstrap_results[n_bootstraps] = bootstrap_results

    # Concatenar todas las métricas en un solo DataFrame
    all_metrics_df = pd.concat(all_metrics)

    # Guardar las métricas en un archivo CSV
    metrics_csv_path = os.path.join(run_dir, "bootstrap_metrics.csv")
    all_metrics_df.to_csv(metrics_csv_path, index=False)
    print(f"Métricas de bootstrap guardadas en: {metrics_csv_path}")

    # Seleccionar el 'n' con las mejores métricas (ejemplo: menor MAE promedio)
    best_n = all_metrics_df.groupby('n_bootstrap')['mae'].mean().idxmin()
    print(f"El número de bootstraps con el menor MAE promedio es: {best_n}")

    # Seleccionar las curvas de bootstrap correspondientes al mejor 'n'
    best_bootstrap_curves = all_bootstrap_results[best_n]

    # Calcular la curva promedio del mejor bootstrap
    if best_bootstrap_curves:
        combined_best_bootstrap = pd.concat(best_bootstrap_curves)
        best_bootstrap_rate = combined_best_bootstrap.groupby('AGE')['VADM_rate_of_change'].mean().reset_index()
    else:
        best_bootstrap_rate = calculate_vadm_rate_of_change(data_vadm_clean.copy(), window_step=0.05)
        print("No se encontraron curvas de bootstrap para el mejor n, usando la curva original.")

    # Graficar la curva de bootstrap que mejor se ajustó (usando la curva promedio) junto con el scatter de PINT
    plot_bootstrap_curve(data_vadm_clean, best_bootstrap_rate, pint_10my, run_dir)

    # Graficar la tasa de cambio de VADM y los subchrones
    original_rate_df = calculate_vadm_rate_of_change(data_vadm_clean.copy(), window_step=0.05)
    plot_vadm_rate_of_change_with_subchrons(original_rate_df[original_rate_df['AGE'] <= 5.0], 0.05, run_dir, subchrones)

    # Graficar todas los n de bootstrap vs la métrica (MAE como ejemplo)
    plot_metrics_vs_n_bootstrap(all_metrics_df, run_dir)

    # Evaluar la estabilidad alrededor del mejor 'n'
    stability_df = evaluate_stability(data_vadm_clean, best_n, window_step=0.05)

    # Graficar la estabilidad de las métricas
    plot_stability_metrics(stability_df, run_dir)

    print("Análisis de bootstrap completado y gráficos guardados en:", run_dir)




###-----SIMULACIONES---------

# Cargar datos (reemplaza con las rutas correctas)
data_vadm = pd.read_csv('age_vs_vadm')
df_plot = pd.read_csv('RW_vs_vadm').dropna(subset=['mean_VADM', 'std_VADM'])

# Preparar datos
x = df_plot['window'].values
y_mean = df_plot['mean_VADM'].values
y_std = df_plot['std_VADM'].values

# Número de simulaciones de Monte Carlo
n_simulations = 500

# Almacenar errores cuadráticos medios (MSE)
mse_values = []

# Rango de edades para evaluar las splines
x_new = np.linspace(x.min(), x.max(), 200)

# Realizar las simulaciones
for i in range(n_simulations):
    # Generar datos simulados a partir de la distribución normal
    y_simulated = np.random.normal(y_mean, y_std)

    # Asegurarse de que los datos simulados no tengan valores NaN o infinitos
    y_simulated = np.nan_to_num(y_simulated, nan=np.nanmean(y_simulated))

    # Interpolar con spline cúbica
    try:
        cs = CubicSpline(x, y_simulated)
    except ValueError as e:
        print(f"Error interpolando en la simulación {i}: {e}")
        continue

    # Evaluar la spline en el rango de edades
    y_predicted = cs(x_new)

    # Calcular MSE comparando con los datos originales (usando y_mean como referencia)
    mse = mean_squared_error(cs(x), y_mean) #mse = mean_squared_error(y_predicted, np.interp(x_new, x, y_mean))
    mse_values.append(mse)

# Analizar los resultados de Monte Carlo
mse_mean = np.mean(mse_values)
mse_std = np.std(mse_values)

print(f"MSE medio: {mse_mean:.4f}")
print(f"Desviación estándar del MSE: {mse_std:.4f}")

# Visualizar el MSE
plt.figure(figsize=(10, 6))
plt.hist(mse_values, bins=30, color='skyblue', edgecolor='black')
plt.title('Distribución del Error Cuadrático Medio (Monte Carlo)')
plt.xlabel('MSE')
plt.ylabel('Frecuencia')
plt.savefig('monte_carlo_mse_distribution.png', dpi=300)
plt.show()

#bootstrap validation

#Load the same data used before for bootstrap and mc analysis
data_vadm = pd.read_csv('age_vs_vadm')
df_plot = pd.read_csv('RW_vs_vadm').dropna(subset=['mean_VADM'])

#Set up the validation cross method (K-Fold)
X = df_plot['window'].values
y = df_plot['mean_VADM'].values
n_splits = 5 #Amount of splits (cross validations) to apply through the data

kf = KFold(n_splits = n_splits, shuffle = True, random_state = 42) #State 42 is a commom use, but every number is ok for its use

#Initialize metrics acumulators
mse_scores = []
mae_scores = []
r2_scores = []

#Iterating every splitted data for model training and prediction
for train_index, test_index in kf.split(X):
    #Split train and test data
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]

    #Model fitting (Cubic Spline)
    cs = CubicSpline(X_train, y_train)

    #Prediction on to test data
    y_pred = cs(X_test)

    #Metrics acumulation
    mse_scores.append(mean_squared_error(y_test, y_pred))
    mae_scores.append(mean_absolute_error(y_test, y_pred))
    r2_scores.append(r2_score(y_test, y_pred))

#Convert to numpy array in order to show the mean and std
mse_scores = np.array(mse_scores)
mae_scores = np.array(mae_scores)
r2_scores = np.array(r2_scores)

#Showing metrics
print("Resultados de la validación cruzada:")
print(f"MSE: Media={mse_scores.mean():.4f}, Desviación estándar={mse_scores.std():.4f}")
print(f"MAE: Media={mae_scores.mean():.4f}, Desviación estándar={mae_scores.std():.4f}")
print(f"R2: Media={r2_scores.mean():.4f}, Desviación estándar={r2_scores.std():.4f}")


#Montecarlo test

# Data load
data_vadm = pd.read_csv('age_vs_vadm')

# Parametros que seran testados
window_sizes = [0.05, 0.1, 0.2]
interpolation_methods = ['linear', 'cubic']

#Resultados do teste
results = []

#Test iteractions
for window_size in window_sizes:
    for interpolation_method in interpolation_methods:
        #Rolling window method
        df_plot = data_vadm.copy()
        x = df_plot['AGE'].values
        y = df_plot['VADM'].values

        #Calculate mean within sliding window using pandas API
        rolling_mean = df_plot['VADM'].rolling(window = int(len(df_plot)*window_size), min_periods = 1, center = True).mean() #Define how many values will be used
        results.append([window_size, interpolation_method, rolling_mean]) #Apend results to show then

#Creates a plot to show the results visually
plt.figure(figsize=(12, 6))
for window_size, interpolation_method, rolling_mean in results:
    plt.plot(x, rolling_mean, label=f'Window={window_size}, Interp={interpolation_method}')

plt.xlabel("AGE - MILLIONS YEARS")
plt.ylabel("Mean VADM")
plt.title("Sensitivity: Rolling Windows")
plt.legend()
plt.show()


# Data Load
data_vadm = pd.read_csv('age_vs_vadm')
df_plot = pd.read_csv('RW_vs_vadm').dropna(subset=['mean_VADM'])

# Interative Chart function

fig = go.Figure()

fig.add_trace(go.Scatter(x=data_vadm['AGE'], y=data_vadm['VADM'], mode='markers', name='Original Data'))
fig.add_trace(go.Scatter(x=df_plot['window'], y=df_plot['mean_VADM'], mode='lines', name='Rolling Window'))

fig.update_layout(title='VADM vs. AGE (Interactive)',
                  xaxis_title='Age (Ma)',
                  yaxis_title='VADM (x10^22 Am²)')

fig.show()
